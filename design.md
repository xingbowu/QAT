# QAT (Question Answering Transformer) ä»£ç é€»è¾‘åˆ†æ

## ğŸ“‹ ç›®å½•
- [1. é¡¹ç›®æ¦‚è¿°](#1-é¡¹ç›®æ¦‚è¿°)
- [2. æ‰§è¡Œæµç¨‹æ€»è§ˆ](#2-æ‰§è¡Œæµç¨‹æ€»è§ˆ)
- [3. å…¥å£è„šæœ¬åˆ†æ](#3-å…¥å£è„šæœ¬åˆ†æ-run_csqash)
- [4. ä¸»ç¨‹åºæµç¨‹](#4-ä¸»ç¨‹åºæµç¨‹-main_qatpy)
- [5. æ•°æ®åŠ è½½æ¨¡å—](#5-æ•°æ®åŠ è½½æ¨¡å—)
- [6. æ¨¡å‹æ¶æ„](#6-æ¨¡å‹æ¶æ„)
- [7. è®­ç»ƒæµç¨‹](#7-è®­ç»ƒæµç¨‹)
- [8. å…³é”®ç»„ä»¶è¯¦è§£](#8-å…³é”®ç»„ä»¶è¯¦è§£)
- [9. æ•°æ®æµå›¾](#9-æ•°æ®æµå›¾)

---

## 1. é¡¹ç›®æ¦‚è¿°

**QAT (Relation-aware Language-Graph Transformer)** æ˜¯ä¸€ä¸ªç”¨äºçŸ¥è¯†å›¾è°±å¢å¼ºçš„é—®ç­”ç³»ç»Ÿï¼Œå‘è¡¨äº AAAI 2023ã€‚

### æ ¸å¿ƒç‰¹æ€§
- **åŒç¼–ç å™¨æ¶æ„**ï¼šè¯­è¨€æ¨¡å‹ï¼ˆRoBERTaï¼‰+ å›¾Transformer
- **å…³ç³»æ„ŸçŸ¥**ï¼šå¤„ç†çŸ¥è¯†å›¾è°±ä¸­çš„å…³ç³»è·¯å¾„
- **å¤šä»»åŠ¡æ”¯æŒ**ï¼šCommonsenseQAã€OpenBookQAã€MedQA-USMLE

### æŠ€æœ¯æ ˆ
- PyTorch 2.1.0 + CUDA 12.1
- PyTorch Geometric (å›¾ç¥ç»ç½‘ç»œ)
- Transformers (é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹)
- GloVe (è¯å‘é‡åŒ¹é…)

---

## 2. æ‰§è¡Œæµç¨‹æ€»è§ˆ

```
bash run_csqa.sh
    â†“
è®¾ç½®ç¯å¢ƒå˜é‡å’Œè¶…å‚æ•°
    â†“
python3 main_qat.py (å¸¦å‚æ•°)
    â†“
1. è§£æå‚æ•°
2. åŠ è½½æ•°æ® (LM_QAT_DataLoader)
3. æ„å»ºæ¨¡å‹ (LM_QAT)
4. è®­ç»ƒå¾ªç¯ (trainå‡½æ•°)
5. è¯„ä¼°å’Œä¿å­˜
```

---

## 3. å…¥å£è„šæœ¬åˆ†æ (run_csqa.sh)

### 3.1 ç¯å¢ƒé…ç½®

```bash
# æŒ‡å®šä½¿ç”¨çš„GPU
export CUDA_VISIBLE_DEVICES=6,7

# è·å–æ—¶é—´æˆ³ï¼Œç”¨äºæ—¥å¿—æ–‡ä»¶å‘½å
dt=`date '+%Y%m%d_%H%M%S'`
```

### 3.2 æ•°æ®å’Œæ¨¡å‹è·¯å¾„

```bash
dataset="csqa"                                    # æ•°æ®é›†åç§°
data_dir="/data1/dataset/qat_data"               # æ•°æ®æ ¹ç›®å½•
model='/data1/models/FacebookAI/roberta-large'  # é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
```

### 3.3 è¶…å‚æ•°é…ç½®

| å‚æ•°ç±»åˆ« | å‚æ•°å | å€¼ | è¯´æ˜ |
|---------|--------|-----|------|
| **è®­ç»ƒé…ç½®** | n_epochs | 30 | è®­ç»ƒè½®æ•° |
| | bs | 128 | æ‰¹æ¬¡å¤§å° |
| | mbs | 4 | mini batch size |
| | ebs | 8 | è¯„ä¼°æ‰¹æ¬¡å¤§å° |
| **å­¦ä¹ ç‡** | elr | 2e-5 | ç¼–ç å™¨å­¦ä¹ ç‡ |
| | dlr | 1e-4 | è§£ç å™¨å­¦ä¹ ç‡ |
| | weight_decay | 1e-2 | æƒé‡è¡°å‡ |
| **æ¨¡å‹ç»“æ„** | tr_dim | 1024 | Transformerç»´åº¦ |
| | ffn_dim | 2048 | å‰é¦ˆç½‘ç»œç»´åº¦ |
| | num_heads | 16 | æ³¨æ„åŠ›å¤´æ•° |
| | k | 2 | Transformerå±‚æ•° |
| **æ­£åˆ™åŒ–** | dropout | 0.1 | Dropoutç‡ |
| | dropoutf | 0.1 | å…¨è¿æ¥å±‚Dropout |
| | drop_ratio | 0.05 | è¾¹åˆ é™¤æ¯”ä¾‹ |
| **å…¶ä»–** | lambda | 10 | RPEæ­£åˆ™åŒ–ç³»æ•° |

### 3.4 è®­ç»ƒå‘½ä»¤

```bash
python3 -u main_qat.py \
    --dataset $dataset \
    --encoder $model \
    -k $k --inhouse false \
    --train_adj ${data_dir}/${dataset}/graph/train.graph.adj.ori2.metapath.2.q2a.seq.pk \
    --dev_adj ${data_dir}/${dataset}/graph/dev.graph.adj.ori2.metapath.2.q2a.seq.pk \
    --test_adj ${data_dir}/${dataset}/graph/test.graph.adj.ori2.metapath.2.q2a.seq.pk \
    --train_statements ${data_dir}/${dataset}/statement/train.statement.jsonl \
    --dev_statements ${data_dir}/${dataset}/statement/dev.statement.jsonl \
    --test_statements ${data_dir}/${dataset}/statement/test.statement.jsonl \
    --max_seq_len 88 \
    --num_relation 38 \
    --unfreeze_epoch 4 \
    --lr_schedule "warmup_linear" \
    --save_model \
    --inverse_relation \
    | tee -a $logs_dir_pref/newFT_path.${dataset}...log.txt
```

**å…³é”®å‚æ•°è¯´æ˜**ï¼š
- `--inhouse false`: ä¸ä½¿ç”¨å†…éƒ¨æ•°æ®åˆ’åˆ†
- `--unfreeze_epoch 4`: ç¬¬4è½®å¼€å§‹å¾®è°ƒç¼–ç å™¨
- `--inverse_relation`: ä½¿ç”¨åå‘å…³ç³»
- `--save_model`: ä¿å­˜æœ€ä½³æ¨¡å‹

---

## 4. ä¸»ç¨‹åºæµç¨‹ (main_qat.py)

### 4.1 ç¨‹åºå…¥å£

```python
def main():
    parser = get_parser()  # è·å–åŸºç¡€è§£æå™¨
    # æ·»åŠ æ¨¡å‹ç‰¹å®šå‚æ•°
    parser.add_argument('--mode', default='train', ...)
    parser.add_argument('--transformer_dim', type=int, default=1024, ...)
    # ... æ›´å¤šå‚æ•°
    
    args = parser.parse_args()
    
    if args.mode == 'train':
        train(args)
    elif args.mode == 'eval_detail':
        eval_detail(args)
```

### 4.2 è®­ç»ƒå‡½æ•°æ ¸å¿ƒæµç¨‹

```python
def train(args):
    # 1. è®¾ç½®éšæœºç§å­
    random.seed(args.seed)
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    
    # 2. è®¾ç½®è®¾å¤‡
    device0 = torch.device("cuda:0")  # ç¼–ç å™¨
    device1 = torch.device("cuda:1")  # è§£ç å™¨
    
    # 3. åŠ è½½æ•°æ®
    dataset = LM_QAT_DataLoader(
        args, 
        args.train_statements, args.train_adj,
        args.dev_statements, args.dev_adj,
        args.test_statements, args.test_adj,
        batch_size=args.batch_size,
        eval_batch_size=args.eval_batch_size,
        device=(device0, device1),
        model_name=args.encoder,
        max_node_num=args.max_node_num,
        max_seq_length=args.max_seq_len
    )
    
    # 4. æ„å»ºæ¨¡å‹
    model = LM_QAT(
        args, args.encoder, 
        k=args.k, 
        n_ntype=4,              # 4ç§èŠ‚ç‚¹ç±»å‹
        n_etype=args.num_relation,  # å…³ç³»ç±»å‹æ•°
        fc_dim=args.fc_dim,
        n_fc_layer=args.fc_layer_num,
        p_fc=args.dropoutf,
        pretrained_concept_emb=cp_emb,
        concept_dim=args.transformer_dim
    )
    
    # 5. åˆ†é…æ¨¡å‹åˆ°ä¸åŒGPU
    model.encoder.to(device0)
    model.decoder.to(device1)
    
    # 6. è®¾ç½®ä¼˜åŒ–å™¨
    optimizer = OPTIMIZER_CLASSES[args.optim](grouped_parameters)
    scheduler = get_linear_schedule_with_warmup(...)
    
    # 7. è®­ç»ƒå¾ªç¯
    for epoch_id in range(args.n_epochs):
        if epoch_id == args.unfreeze_epoch:
            unfreeze_net(model.encoder)  # è§£å†»ç¼–ç å™¨
            
        for qids, labels, *input_data in dataset.train():
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            logits, rpe = model(*input_data, qids=qids)
            
            # è®¡ç®—æŸå¤±
            loss = loss_func(logits, labels)
            loss -= rpe.tanh().mean() * args.lambda_rpe  # RPEæ­£åˆ™åŒ–
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            scheduler.step()
        
        # è¯„ä¼°
        dev_acc = evaluate_accuracy(dataset.dev(), model)
        test_acc = evaluate_accuracy(dataset.test(), model)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if dev_acc >= best_dev_acc:
            torch.save([model, args], model_path)
```

---

## 5. æ•°æ®åŠ è½½æ¨¡å—

### 5.1 LM_QAT_DataLoader ç±»

ä½ç½®ï¼š`modeling/modeling_qat.py`

```python
class LM_QAT_DataLoader:
    def __init__(self, args, train_statement_path, train_adj_path, ...):
        # 1. ç¡®å®šæ¨¡å‹ç±»å‹
        model_type = get_model_class_from_name(model_name)
        
        # 2. åŠ è½½è¯­è¨€æ•°æ® (é—®é¢˜+ç­”æ¡ˆæ–‡æœ¬)
        self.train_qids, self.train_labels, *self.train_encoder_data = \
            load_input_tensors(train_statement_path, model_type, model_name, max_seq_length)
        
        # 3. åŠ è½½å›¾æ•°æ® (çŸ¥è¯†å›¾è°±é‚»æ¥çŸ©é˜µå’Œå…ƒè·¯å¾„)
        *self.train_decoder_data, self.train_metapath, self.train_adj_data = \
            load_sparse_adj_data_and_metapathonehot_with_contextnode_changed(
                train_adj_path, max_node_num, num_choice, args
            )
```

### 5.2 æ•°æ®ç»„æˆ

#### 5.2.1 ç¼–ç å™¨æ•°æ®ï¼ˆæ–‡æœ¬ï¼‰
- `input_ids`: åˆ†è¯åçš„token IDs
- `attention_mask`: æ³¨æ„åŠ›æ©ç 
- `token_type_ids`: ç‰‡æ®µç±»å‹IDs
- `output_mask`: è¾“å‡ºæ©ç 

#### 5.2.2 è§£ç å™¨æ•°æ®ï¼ˆå›¾ï¼‰
- `concept_ids`: æ¦‚å¿µèŠ‚ç‚¹IDs
- `node_type_ids`: èŠ‚ç‚¹ç±»å‹ (question/answer/context)
- `adj_lengths`: é‚»æ¥çŸ©é˜µé•¿åº¦
- `edge_index`: è¾¹ç´¢å¼• [2, E]
- `edge_type`: è¾¹ç±»å‹ (å…³ç³»ç±»å‹)
- `metapath_feature`: å…ƒè·¯å¾„ç‰¹å¾
- `metapath_feature_count`: å…ƒè·¯å¾„ç»Ÿè®¡

### 5.3 æ‰¹æ¬¡æ•°æ®æµ

```
load_input_tensors() â†’ Tokenizeæ–‡æœ¬
    â†“
batch_data:
â”œâ”€â”€ qids: [batch_size]
â”œâ”€â”€ labels: [batch_size]
â”œâ”€â”€ input_ids: [batch_size, num_choice, seq_len]
â”œâ”€â”€ attention_mask: [batch_size, num_choice, seq_len]
â””â”€â”€ ...

load_sparse_adj_data...() â†’ æ„å»ºå›¾ç»“æ„
    â†“
graph_data:
â”œâ”€â”€ concept_ids: [batch_size, num_choice, max_nodes]
â”œâ”€â”€ node_type_ids: [batch_size, num_choice, max_nodes]
â”œâ”€â”€ adj_lengths: [batch_size, num_choice]
â”œâ”€â”€ edge_index: List[(2, E_i)]
â”œâ”€â”€ edge_type: List[(E_i,)]
â””â”€â”€ metapath_feature: [batch_size, num_choice, max_path_len]
```

---

## 6. æ¨¡å‹æ¶æ„

### 6.1 æ•´ä½“æ¶æ„ (LM_QAT)

```
Input: Question + Answer Choices + Knowledge Graph
                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   TextEncoder         â”‚
        â”‚   (RoBERTa-Large)     â”‚  device0 (GPU:0)
        â”‚   è¾“å‡º: sent_vecs     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   QAT Decoder         â”‚
        â”‚   (Graph Transformer) â”‚  device1 (GPU:1)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
               QA Score
```

### 6.2 TextEncoder (è¯­è¨€ç¼–ç å™¨)

ä½ç½®ï¼š`modeling/modeling_encoder.py`

```python
class TextEncoder(nn.Module):
    def __init__(self, model_name, ...):
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        self.module = AutoModel.from_pretrained(model_name)
        self.sent_dim = self.module.config.hidden_size  # 1024
    
    def forward(self, input_ids, attention_mask, token_type_ids, output_mask):
        # å‰å‘ä¼ æ’­
        outputs = self.module(
            input_ids, 
            attention_mask=attention_mask,
            token_type_ids=token_type_ids
        )
        
        # æå–[CLS] tokenè¡¨ç¤º
        sent_vecs = outputs[1]  # [batch*num_choice, hidden_size]
        
        return sent_vecs, all_hidden_states
```

**è¾“å…¥ç»´åº¦**ï¼š
- `input_ids`: [batch_size*5, seq_len] (5ä¸ªé€‰é¡¹)
- `attention_mask`: [batch_size*5, seq_len]

**è¾“å‡ºç»´åº¦**ï¼š
- `sent_vecs`: [batch_size*5, 1024]
- `all_hidden_states`: [batch_size*5, seq_len, 1024]

### 6.3 QAT Decoder (å›¾Transformerè§£ç å™¨)

#### 6.3.1 QAT ä¸»æ¨¡å—

```python
class QAT(nn.Module):
    def __init__(self, args, k, n_ntype, n_etype, sent_dim, ...):
        self.qat = FullTransformer(
            layer_num=k,              # 2å±‚
            n_ntype=n_ntype,          # 4ç§èŠ‚ç‚¹ç±»å‹
            n_etype=n_etype,          # 38ç§å…³ç³»
            d_sentence=sent_dim,      # 1024
            d_model=args.transformer_dim,     # 1024
            nhead=args.num_heads,     # 16
            dim_feedforward=args.transformer_ffn_dim  # 2048
        )
    
    def forward(self, sent_vecs, concept_ids, node_type_ids, adj, ...):
        qa_score, rpe = self.qat(
            adj, sent_vecs, node_type_ids, 
            edge_type, lm_all_states, lm_mask, 
            textfeat, metapath_feature, ...
        )
        return qa_score, rpe
```

#### 6.3.2 FullTransformer æ¶æ„

ä½ç½®ï¼š`modeling/modeling_qat.py`

```python
class FullTransformer(nn.Module):
    def __init__(self, layer_num, ...):
        # 1. è¾¹ç¼–ç å™¨
        self.edge_encoder = MLP(
            input_size=8,        # head_type + tail_type + edge_type
            hidden_size=d_model,
            output_size=d_model,
            num_layers=2
        )
        
        # 2. å¥å­æŠ•å½±å±‚
        self.sent_proj = nn.Linear(d_sentence, d_model)
        
        # 3. èŠ‚ç‚¹ç±»å‹åµŒå…¥
        self.ntype_embed = nn.Embedding(n_ntype, d_model)
        
        # 4. Matcher (æ–‡æœ¬-å›¾è°±åŒ¹é…)
        self.matcher = Matcher(encoder_type)
        
        # 5. Transformerå±‚
        self.layers = nn.ModuleList([
            [
                GATLayer(...),           # å›¾æ³¨æ„åŠ›
                nn.LayerNorm(...),
                MultiheadAttention(...), # LMæ³¨æ„åŠ›
                nn.LayerNorm(...),
                FFN(...),                # å‰é¦ˆç½‘ç»œ
                nn.LayerNorm(...)
            ]
            for _ in range(layer_num)
        ])
        
        # 6. è¾“å‡ºæ‰“åˆ†å±‚
        self.qa_scorer = MLP(d_model, d_model, 1, num_layers=2)
```

**å‰å‘ä¼ æ’­æµç¨‹**ï¼š

```python
def forward(self, adj, sent_vecs, node_type_ids, edge_type, ...):
    # 1. ç¼–ç è¾¹
    edge_embeddings = self.edge_encoder(
        torch.cat([edge_vec, headtail_vec], dim=1)
    )
    
    # 2. åˆå§‹åŒ–èŠ‚ç‚¹ç‰¹å¾
    tgt = self.sent_proj(sent_vecs)  # [B*5, d_model]
    tgt = tgt + self.ntype_embed(node_type_ids[:, 0])
    
    # 3. æ–‡æœ¬-å›¾è°±åŒ¹é…
    lm_to_kg_attn = self.matcher.match(
        lm_tokens, lm_mask, kg_tokens, kg_types, qids, device
    )
    
    # 4. Transformerå±‚è¿­ä»£
    for layer in self.layers:
        # 4.1 å›¾æ³¨æ„åŠ› (èŠ‚ç‚¹é—´ä¿¡æ¯ä¼ æ’­)
        tgt2, rpe = layer[0](  # GATLayer
            tgt, edge_index, edge_embeddings, 
            node_type_ids, metapath_feature
        )
        tgt = tgt + layer[1](tgt2)  # æ®‹å·® + LayerNorm
        
        # 4.2 è¯­è¨€æ¨¡å‹æ³¨æ„åŠ› (æ–‡æœ¬ä¿¡æ¯èåˆ)
        tgt2 = layer[2](  # MultiheadAttention
            query=tgt,
            key=lm_all_states,
            value=lm_all_states,
            attn_mask=lm_to_kg_attn
        )
        tgt = tgt + layer[3](tgt2)  # æ®‹å·® + LayerNorm
        
        # 4.3 å‰é¦ˆç½‘ç»œ
        tgt2 = layer[4](tgt)  # FFN
        tgt = tgt + layer[5](tgt2)  # æ®‹å·® + LayerNorm
    
    # 5. è®¡ç®—æœ€ç»ˆå¾—åˆ†
    graph_score = self.qa_scorer(tgt[:, 0, :])  # ä½¿ç”¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹
    
    return graph_score, rpe
```

### 6.4 å…³é”®å­æ¨¡å—

#### 6.4.1 GATLayer (å›¾æ³¨æ„åŠ›å±‚)

```python
class GATLayer(MessagePassing):
    def forward(self, x, edge_index, edge_attr, node_type, metapath):
        # æ¶ˆæ¯ä¼ é€’
        out = self.propagate(
            edge_index, 
            x=x, 
            edge_attr=edge_attr,
            node_type=node_type
        )
        
        # ç›¸å¯¹ä½ç½®ç¼–ç  (RPE)
        rpe = self.compute_rpe(metapath, x)
        
        return out, rpe
```

#### 6.4.2 Matcher (æ–‡æœ¬-å›¾è°±åŒ¹é…å™¨)

```python
class Matcher:
    def __init__(self, encoder):
        # GloVeè¯å‘é‡
        self.GloVe = GloVe(name='840B', dim=300)
        # çŸ¥è¯†å›¾è°±å®ä½“
        self.KG_entities = load_entities('data/cpnet/concept_cor.txt')
        # è¯­è¨€æ¨¡å‹åˆ†è¯å™¨
        self.LM_tokenizer = AutoTokenizer.from_pretrained(encoder)
    
    def match(self, lm_tokens, lm_mask, kg_tokens, kg_types, qids, device):
        # 1. å°†LM tokensè½¬ä¸ºGloVeè¡¨ç¤º
        lm_words = self.LM_tokenizer.convert_ids_to_tokens(lm_tokens)
        lm_glove = self.GloVe.get_vecs_by_tokens(lm_words)
        
        # 2. å°†KG entitiesè½¬ä¸ºGloVeè¡¨ç¤º
        kg_words = [self.KG_entities[id] for id in kg_tokens]
        kg_glove = self.GloVe.get_vecs_by_tokens(kg_words)
        
        # 3. è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ (ä½™å¼¦ç›¸ä¼¼åº¦)
        similarity = F.cosine_similarity(
            lm_glove.unsqueeze(2),  # [B, L, 1, D]
            kg_glove.unsqueeze(1),  # [B, 1, N, D]
            dim=-1
        )  # [B, L, N]
        
        # 4. ç”Ÿæˆæ³¨æ„åŠ›æ©ç 
        attn_mask = (similarity > threshold).float()
        
        return attn_mask
```

**ä½œç”¨**ï¼šé€šè¿‡GloVeè¯å‘é‡è®¡ç®—æ–‡æœ¬tokenå’ŒçŸ¥è¯†å›¾è°±èŠ‚ç‚¹çš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œç”Ÿæˆæ³¨æ„åŠ›æ©ç ï¼Œå¼•å¯¼æ¨¡å‹å…³æ³¨è¯­ä¹‰ç›¸å…³çš„çŸ¥è¯†ã€‚

---

## 7. è®­ç»ƒæµç¨‹

### 7.1 è®­ç»ƒå¾ªç¯

```python
for epoch_id in range(args.n_epochs):
    # 1. ç¼–ç å™¨å†»ç»“/è§£å†»æ§åˆ¶
    if epoch_id == args.unfreeze_epoch:  # ç¬¬4è½®
        unfreeze_net(model.encoder)
    if epoch_id == args.refreeze_epoch:
        freeze_net(model.encoder)
    
    # 2. æ‰¹æ¬¡è®­ç»ƒ
    for qids, labels, *input_data in dataset.train():
        optimizer.zero_grad()
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        with torch.cuda.amp.autocast():
            # å‰å‘ä¼ æ’­
            logits, rpe = model(*input_data, qids=qids)
            
            # æŸå¤±è®¡ç®—
            loss = loss_func(logits, labels)
            loss -= rpe.tanh().mean() * args.lambda_rpe
        
        # åå‘ä¼ æ’­
        scaler.scale(loss).backward()
        
        # æ¢¯åº¦è£å‰ª
        nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)
        
        # ä¼˜åŒ–å™¨æ›´æ–°
        scaler.step(optimizer)
        scaler.update()
        scheduler.step()
    
    # 3. è¯„ä¼°
    dev_acc = evaluate_accuracy(dataset.dev(), model)
    test_acc = evaluate_accuracy(dataset.test(), model)
    
    # 4. æ—©åœæ£€æŸ¥
    if epoch_id - best_dev_epoch >= args.max_epochs_before_stop:
        break
```

### 7.2 æŸå¤±å‡½æ•°

```python
# ä¸»æŸå¤±ï¼šäº¤å‰ç†µ
loss = CrossEntropyLoss(logits, labels)

# æ­£åˆ™åŒ–ï¼šç›¸å¯¹ä½ç½®ç¼–ç 
rpe_reg = rpe.tanh().mean() * lambda_rpe  # lambda=10

# æ€»æŸå¤±
total_loss = loss - rpe_reg
```

**RPEæ­£åˆ™åŒ–ä½œç”¨**ï¼š
- é¼“åŠ±æ¨¡å‹å­¦ä¹ æ›´å¥½çš„ç›¸å¯¹ä½ç½®ç¼–ç 
- æå‡æ¨¡å‹å¯¹å›¾ç»“æ„çš„ç†è§£èƒ½åŠ›

### 7.3 è¯„ä¼°å‡½æ•°

```python
def evaluate_accuracy(eval_set, model):
    n_samples, n_correct = 0, 0
    model.eval()
    
    with torch.no_grad():
        for qids, labels, *input_data in eval_set:
            logits, _ = model(*input_data, qids=qids)
            
            # è®¡ç®—å‡†ç¡®ç‡
            n_correct += (logits.argmax(1) == labels).sum().item()
            n_samples += labels.size(0)
    
    return n_correct / n_samples
```

---

## 8. å…³é”®ç»„ä»¶è¯¦è§£

### 8.1 åŒGPUç­–ç•¥

```
GPU 0 (device0):
â”œâ”€â”€ TextEncoder (RoBERTa-Large)
â”‚   â””â”€â”€ å‚æ•°é‡: ~355M
â”‚   â””â”€â”€ å†…å­˜å ç”¨: ~1.5GB (FP16)
â””â”€â”€ è¾“å‡º: sent_vecs, lm_states

GPU 1 (device1):
â”œâ”€â”€ QAT Decoder (Graph Transformer)
â”‚   â””â”€â”€ å‚æ•°é‡: ~50M
â”‚   â””â”€â”€ å†…å­˜å ç”¨: ~0.5GB (FP16)
â””â”€â”€ è¾“å‡º: qa_score
```

**ä¼˜åŠ¿**ï¼š
1. åˆ†æ•£å†…å­˜å‹åŠ›
2. å¹¶è¡Œè®¡ç®—
3. æ”¯æŒæ›´å¤§æ‰¹æ¬¡

### 8.2 æ¸è¿›å¼è§£å†»ç­–ç•¥

```
Epoch 0-3:
â”œâ”€â”€ Encoder: å†»ç»“ â„ï¸
â””â”€â”€ Decoder: è®­ç»ƒ ğŸ”¥

Epoch 4-29:
â”œâ”€â”€ Encoder: è§£å†» ğŸ”¥
â””â”€â”€ Decoder: è®­ç»ƒ ğŸ”¥
```

**åŸå› **ï¼š
1. é¿å…é¢„è®­ç»ƒçŸ¥è¯†ä¸¢å¤±
2. å…ˆè®©è§£ç å™¨é€‚åº”ç¼–ç å™¨è¾“å‡º
3. åæœŸå¾®è°ƒæ•´ä½“ç³»ç»Ÿ

### 8.3 æ··åˆç²¾åº¦è®­ç»ƒ

```python
scaler = torch.cuda.amp.GradScaler()

with torch.cuda.amp.autocast():
    # FP16å‰å‘ä¼ æ’­
    logits, rpe = model(...)
    loss = loss_func(...)

# FP32åå‘ä¼ æ’­
scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

**åŠ é€Ÿæ•ˆæœ**ï¼š
- è®­ç»ƒé€Ÿåº¦æå‡ 2-3x
- å†…å­˜ä½¿ç”¨å‡å°‘ 40-50%

### 8.4 å­¦ä¹ ç‡è°ƒåº¦

```python
# Warmup + Linear Decay
scheduler = get_linear_schedule_with_warmup(
    optimizer,
    num_warmup_steps=150,
    num_training_steps=max_steps
)
```

```
Learning Rate
    â†‘
    â”‚     â•±â”€â”€â”€â”€â•²
    â”‚    â•±      â•²___
    â”‚   â•±           â•²___
    â”‚  â•±                â•²___
    â”‚ â•±                     â•²___
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Steps
     warmup   training phase
```

---

## 9. æ•°æ®æµå›¾

### 9.1 å®Œæ•´æ•°æ®æµ

```
åŸå§‹æ•°æ®
â”œâ”€â”€ Statement JSONL (é—®é¢˜+ç­”æ¡ˆ)
â”‚   â””â”€â”€ {"id": "...", "question": {...}, "answer": {...}}
â”‚
â””â”€â”€ Graph PKL (çŸ¥è¯†å›¾è°±)
    â””â”€â”€ {adj_matrix, edge_types, metapaths, ...}
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Data Loading                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Tokenization   â”‚  â”‚  Graph Building  â”‚  â”‚
â”‚  â”‚  (RoBERTa)     â”‚  â”‚  (ConceptNet)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Encoder Data   â”‚   â”‚  Decoder Data    â”‚
â”‚  - input_ids    â”‚   â”‚  - concept_ids   â”‚
â”‚  - attn_mask    â”‚   â”‚  - node_types    â”‚
â”‚  - token_types  â”‚   â”‚  - edge_index    â”‚
â”‚  - output_mask  â”‚   â”‚  - edge_types    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  - metapaths     â”‚
        â†“              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                      â†“
        â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚  Device Transfer â”‚
        â”‚              â”‚  CPU â†’ GPU1      â”‚
        â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                      â†“
        â†“              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                          â”‚
â”‚  TextEncoder     â”‚  â”‚  QAT Decoder             â”‚
â”‚  (GPU0)          â”‚  â”‚  (GPU1)                  â”‚
â”‚                  â”‚  â”‚                          â”‚
â”‚  RoBERTa-Large   â”‚  â”‚  1. Edge Encoding        â”‚
â”‚     â†“            â”‚  â”‚  2. Node Init            â”‚
â”‚  sent_vecs       â”‚â”€â”€â†’  3. Text-Graph Matching  â”‚
â”‚  lm_states       â”‚  â”‚  4. Transformer Layers   â”‚
â”‚                  â”‚  â”‚     - GAT                â”‚
â”‚                  â”‚  â”‚     - LM Attention       â”‚
â”‚                  â”‚  â”‚     - FFN                â”‚
â”‚                  â”‚  â”‚  5. QA Scoring           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  QA Scores       â”‚
                      â”‚  [batch, 5]      â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  Loss + Backward â”‚
                      â”‚  - CE Loss       â”‚
                      â”‚  - RPE Reg       â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.2 å•ä¸ªæ ·æœ¬æ•°æ®æµ

```
Question: "Where would I not want a fox?"
Choices:
  A. hen house
  B. arctic tundra
  C. movie theater
  D. english hunt
  E. florida

Knowledge Graph (ConceptNet):
  fox ---related_to--â†’ animal
  hen_house ---used_for--â†’ chickens
  chickens ---is_a--â†’ bird
  fox ---capable_of--â†’ hunt
  ...

Processing:
1. Tokenize:
   [CLS] Where would I not want a fox ? [SEP] hen house [SEP]
   
2. Graph Construction:
   Nodes: [fox, hen_house, animal, chickens, hunt, ...]
   Edges: [(fox, animal), (hen_house, chickens), ...]
   
3. Encoding:
   sent_vecs: [1, 1024]
   lm_states: [1, 88, 1024]
   
4. Graph Reasoning:
   fox â†’ hen_house â†’ chickens
   Attention weights: high similarity
   
5. Prediction:
   Scores: [0.9, 0.1, 0.05, 0.03, 0.02]
   Answer: A (hen house) âœ“
```

---

## 10. æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 10.1 è®¡ç®—ä¼˜åŒ–

| ç­–ç•¥ | æ–¹æ³• | æ•ˆæœ |
|-----|------|------|
| **æ··åˆç²¾åº¦** | AMP (FP16/FP32) | é€Ÿåº¦â†‘2-3x, å†…å­˜â†“40% |
| **æ¢¯åº¦ç´¯ç§¯** | mini_batch_size=4 | æ¨¡æ‹Ÿå¤§æ‰¹æ¬¡ |
| **åŒGPU** | ç¼–ç å™¨/è§£ç å™¨åˆ†ç¦» | å†…å­˜åˆ†æ•£ |
| **ç¼“å­˜** | é¢„å¤„ç†æ•°æ®ç¼“å­˜ | åŠ è½½é€Ÿåº¦â†‘10x |

### 10.2 å†…å­˜ä¼˜åŒ–

```python
# 1. æ¸è¿›å¼åŠ è½½
for batch in dataloader:
    # åªåŠ è½½å½“å‰æ‰¹æ¬¡
    pass

# 2. åŠæ—¶é‡Šæ”¾
del intermediate_results
torch.cuda.empty_cache()

# 3. æ¢¯åº¦æ£€æŸ¥ç‚¹
torch.utils.checkpoint.checkpoint(layer, x)
```

### 10.3 è®­ç»ƒæŠ€å·§

1. **å­¦ä¹ ç‡ç­–ç•¥**ï¼šç¼–ç å™¨ < è§£ç å™¨ (2e-5 vs 1e-4)
2. **æƒé‡è¡°å‡**ï¼šL2æ­£åˆ™åŒ– (1e-2)
3. **Dropout**ï¼š0.1 (é˜²æ­¢è¿‡æ‹Ÿåˆ)
4. **æ—©åœ**ï¼šdevä¸æå‡10è½®ååœæ­¢
5. **æ¢¯åº¦è£å‰ª**ï¼šmax_norm=1.0

---

## 11. æ–‡ä»¶ç»“æ„è¯´æ˜

```
QAT/
â”œâ”€â”€ run_csqa.sh              # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ main_qat.py              # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ setup.sh                 # ç¯å¢ƒå®‰è£…
â”‚
â”œâ”€â”€ modeling/
â”‚   â”œâ”€â”€ modeling_encoder.py # æ–‡æœ¬ç¼–ç å™¨
â”‚   â”œâ”€â”€ modeling_qat.py      # å›¾Transformer
â”‚   â”œâ”€â”€ multihead_attention.py
â”‚   â””â”€â”€ medqa_dataset.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ data_utils.py        # æ•°æ®åŠ è½½
â”‚   â”œâ”€â”€ data_utils_path.py   # è·¯å¾„ç›¸å…³æ•°æ®
â”‚   â”œâ”€â”€ parser_utils.py      # å‚æ•°è§£æ
â”‚   â”œâ”€â”€ optimization_utils.py # ä¼˜åŒ–å™¨
â”‚   â””â”€â”€ layers.py            # è‡ªå®šä¹‰å±‚
â”‚
â””â”€â”€ data/                    # æ•°æ®ç›®å½• (ç¬¦å·é“¾æ¥)
    â”œâ”€â”€ cpnet/              # ConceptNet
    â”œâ”€â”€ csqa/               # CommonsenseQA
    â”‚   â”œâ”€â”€ statement/      # é—®é¢˜ç­”æ¡ˆ
    â”‚   â””â”€â”€ graph/          # çŸ¥è¯†å›¾è°±
    â””â”€â”€ ddb/                # å®ä½“åµŒå…¥
```


---

## 12. è®­ç»ƒæ¨¡å‹æ–‡ä»¶ç»“æ„ (model.pt)

### 12.1 ä¿å­˜æ ¼å¼

è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹è¢«ä¿å­˜ä¸º `model.pt` æ–‡ä»¶ï¼Œä¿å­˜ä½ç½®ï¼š`./saved_models/qat/model.pt`

**ä¿å­˜ä»£ç **ï¼š
```python
# main_qat.py ç¬¬331è¡Œ
torch.save([model, args], model_path)
```

**æ–‡ä»¶ç»“æ„**ï¼š
```
model.pt (Python List)
â”œâ”€â”€ [0] model (LM_QAT å¯¹è±¡)
â”‚   â””â”€â”€ åŒ…å«å®Œæ•´çš„æ¨¡å‹ç»“æ„å’Œæ‰€æœ‰æƒé‡å‚æ•°
â””â”€â”€ [1] args (Namespace å¯¹è±¡)
    â””â”€â”€ åŒ…å«æ‰€æœ‰è®­ç»ƒé…ç½®å‚æ•°
```

### 12.2 è¯¦ç»†å†…å®¹

#### 12.2.1 model å¯¹è±¡å±‚æ¬¡ç»“æ„

```
LM_QAT (æ€»å‚æ•°: ~405M, ~1.5GB)
â”‚
â”œâ”€â”€ encoder: TextEncoder
â”‚   â”œâ”€â”€ module: RobertaModel (~355Må‚æ•°)
â”‚   â”‚   â”œâ”€â”€ embeddings
â”‚   â”‚   â”‚   â”œâ”€â”€ word_embeddings [50265, 1024]
â”‚   â”‚   â”‚   â”œâ”€â”€ position_embeddings [514, 1024]
â”‚   â”‚   â”‚   â””â”€â”€ token_type_embeddings [1, 1024]
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ encoder (24ä¸ªTransformerå±‚)
â”‚   â”‚   â”‚   â””â”€â”€ layer[0-23]
â”‚   â”‚   â”‚       â”œâ”€â”€ attention.self.query [1024, 1024]
â”‚   â”‚   â”‚       â”œâ”€â”€ attention.self.key [1024, 1024]
â”‚   â”‚   â”‚       â”œâ”€â”€ attention.self.value [1024, 1024]
â”‚   â”‚   â”‚       â”œâ”€â”€ attention.output.dense [1024, 1024]
â”‚   â”‚   â”‚       â”œâ”€â”€ intermediate.dense [1024, 4096]
â”‚   â”‚   â”‚       â””â”€â”€ output.dense [4096, 1024]
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ pooler.dense [1024, 1024]
â”‚   â”‚
â”‚   â”œâ”€â”€ sent_dim: 1024
â”‚   â””â”€â”€ model_type: 'roberta'
â”‚
â””â”€â”€ decoder: QAT
    â””â”€â”€ qat: FullTransformer (~50Må‚æ•°)
        â”œâ”€â”€ sent_proj [1024, 1024]
        â”œâ”€â”€ ntype_embed [4, 1024]
        â”‚
        â”œâ”€â”€ edge_encoder: MLP
        â”‚   â”œâ”€â”€ layer_0 [8, 1024]
        â”‚   â”œâ”€â”€ layer_1 [1024, 1024]
        â”‚   â””â”€â”€ output [1024, 1024]
        â”‚
        â”œâ”€â”€ matcher: Matcher
        â”‚   â”œâ”€â”€ GloVe: è¯å‘é‡
        â”‚   â”œâ”€â”€ KG_entities: List[str]
        â”‚   â””â”€â”€ LM_tokenizer: RobertaTokenizer
        â”‚
        â”œâ”€â”€ layers: ModuleList (2å±‚)
        â”‚   â””â”€â”€ [0-1] æ¯å±‚åŒ…å«:
        â”‚       â”œâ”€â”€ [0] GATLayer
        â”‚       â”‚   â”œâ”€â”€ lin [1024, 1024]
        â”‚       â”‚   â””â”€â”€ att [1, 1024]
        â”‚       â”œâ”€â”€ [1] LayerNorm [1024]
        â”‚       â”œâ”€â”€ [2] MultiheadAttention
        â”‚       â”‚   â”œâ”€â”€ q_proj [1024, 1024]
        â”‚       â”‚   â”œâ”€â”€ k_proj [1024, 1024]
        â”‚       â”‚   â”œâ”€â”€ v_proj [1024, 1024]
        â”‚       â”‚   â””â”€â”€ out_proj [1024, 1024]
        â”‚       â”œâ”€â”€ [3] LayerNorm [1024]
        â”‚       â”œâ”€â”€ [4] FFN
        â”‚       â”‚   â”œâ”€â”€ linear1 [1024, 2048]
        â”‚       â”‚   â””â”€â”€ linear2 [2048, 1024]
        â”‚       â””â”€â”€ [5] LayerNorm [1024]
        â”‚
        â””â”€â”€ qa_scorer: MLP
            â”œâ”€â”€ layer_0 [1024, 1024]
            â””â”€â”€ output [1024, 1]
```

#### 12.2.2 args å¯¹è±¡ (è®­ç»ƒé…ç½®)

```python
Namespace(
    # === æ•°æ®é›†é…ç½® ===
    dataset='csqa',
    encoder='/data1/models/FacebookAI/roberta-large',
    train_statements='/.../csqa/statement/train.statement.jsonl',
    dev_statements='/.../csqa/statement/dev.statement.jsonl',
    test_statements='/.../csqa/statement/test.statement.jsonl',
    train_adj='/.../csqa/graph/train.graph.adj.ori2.metapath.2.q2a.seq.pk',
    dev_adj='/.../csqa/graph/dev.graph.adj.ori2.metapath.2.q2a.seq.pk',
    test_adj='/.../csqa/graph/test.graph.adj.ori2.metapath.2.q2a.seq.pk',
    
    # === æ¨¡å‹æ¶æ„ ===
    k=2,                        # Transformerå±‚æ•°
    transformer_dim=1024,       # æ¨¡å‹ç»´åº¦
    transformer_ffn_dim=2048,   # FFNç»´åº¦
    num_heads=16,               # æ³¨æ„åŠ›å¤´æ•°
    max_node_num=44,            # æœ€å¤§èŠ‚ç‚¹æ•°
    max_seq_len=88,             # æœ€å¤§åºåˆ—é•¿åº¦
    num_relation=38,            # å…³ç³»ç±»å‹æ•°
    fc_dim=512,
    fc_layer_num=0,
    
    # === è®­ç»ƒå‚æ•° ===
    batch_size=128,
    mini_batch_size=4,
    eval_batch_size=8,
    encoder_lr=2e-05,           # ç¼–ç å™¨å­¦ä¹ ç‡
    decoder_lr=0.0001,          # è§£ç å™¨å­¦ä¹ ç‡
    weight_decay=0.01,
    n_epochs=30,
    unfreeze_epoch=4,           # ç¬¬4è½®è§£å†»ç¼–ç å™¨
    refreeze_epoch=10000,
    max_epochs_before_stop=10,
    
    # === æ­£åˆ™åŒ– ===
    dropouttr=0.1,
    dropoutf=0.1,
    drop_ratio=0.05,
    lambda_rpe=10.0,
    
    # === ä¼˜åŒ–å™¨é…ç½® ===
    optim='radam',
    lr_schedule='warmup_linear',
    warmup_steps=150,
    max_grad_norm=1.0,
    
    # === å…¶ä»–é…ç½® ===
    seed=0,
    cuda=True,
    save_model=True,
    save_dir='./saved_models/qat/',
    inverse_relation=True,
    add_nodefeatsim='none',
    without_amp=False,
    inhouse=False,
    use_cache=True,
    mode='train',
    ...
)
```

### 12.3 æ–‡ä»¶å¤§å°åˆ†æ

| ç»„ä»¶ | å‚æ•°é‡ | FP32å¤§å° | FP16å¤§å° |
|------|--------|----------|----------|
| **RoBERTaç¼–ç å™¨** | 355M | 1.35GB | 677MB |
| â””â”€ Embeddings | 52M | 208MB | 104MB |
| â””â”€ 24å±‚Transformer | 303M | 1.14GB | 573MB |
| **QATè§£ç å™¨** | 50M | 200MB | 100MB |
| â””â”€ Edge Encoder | 8M | 32MB | 16MB |
| â””â”€ GAT (x2) | 12M | 48MB | 24MB |
| â””â”€ Attention (x2) | 16M | 64MB | 32MB |
| â””â”€ FFN (x2) | 12M | 48MB | 24MB |
| â””â”€ QA Scorer | 2M | 8MB | 4MB |
| **é…ç½®å¯¹è±¡** | - | <1MB | <1MB |
| **æ€»è®¡** | **405M** | **~1.55GB** | **~777MB** |

### 12.4 åŠ è½½å’Œä½¿ç”¨ç¤ºä¾‹

#### ç¤ºä¾‹1: å®Œæ•´åŠ è½½

```python
import torch

# åŠ è½½æ¨¡å‹æ–‡ä»¶
model_path = './saved_models/qat/model.pt'
checkpoint = torch.load(model_path, map_location='cpu')

# è§£åŒ…
model = checkpoint[0]  # LM_QATå¯¹è±¡
args = checkpoint[1]   # Namespaceå¯¹è±¡

print(f"æ¨¡å‹ç±»å‹: {type(model)}")
print(f"æ•°æ®é›†: {args.dataset}")
print(f"ç¼–ç å™¨: {args.encoder}")
print(f"Transformerå±‚æ•°: {args.k}")

# ç§»åŠ¨åˆ°GPU
model.encoder.to('cuda:0')
model.decoder.to('cuda:1')
model.eval()
```

#### ç¤ºä¾‹2: æŸ¥çœ‹æ¨¡å‹è¯¦ç»†ä¿¡æ¯

```python
# åŠ è½½æ¨¡å‹
checkpoint = torch.load('model.pt', map_location='cpu')
model, args = checkpoint[0], checkpoint[1]

# ç»Ÿè®¡å‚æ•°
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

print("=" * 70)
print("æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯")
print("=" * 70)
print(f"æ€»å‚æ•°é‡: {total_params:,}")
print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
print(f"FP32å†…å­˜: {total_params * 4 / (1024**3):.2f} GB")
print(f"FP16å†…å­˜: {total_params * 2 / (1024**3):.2f} GB")

# ç¼–ç å™¨ä¿¡æ¯
encoder_params = sum(p.numel() for p in model.encoder.parameters())
print(f"\nç¼–ç å™¨å‚æ•°: {encoder_params:,} ({encoder_params/total_params*100:.1f}%)")

# è§£ç å™¨ä¿¡æ¯
decoder_params = sum(p.numel() for p in model.decoder.parameters())
print(f"è§£ç å™¨å‚æ•°: {decoder_params:,} ({decoder_params/total_params*100:.1f}%)")

# æ˜¾ç¤ºå‰10å±‚
print("\n" + "=" * 70)
print("æ¨¡å‹å±‚ç»“æ„ (å‰10å±‚)")
print("=" * 70)
for i, (name, param) in enumerate(model.named_parameters()):
    if i < 10:
        print(f"{name:50s} {str(param.shape):20s} {param.numel():>12,}")
    elif i == 10:
        print("...")
        break
```

**è¾“å‡ºç¤ºä¾‹**:
```
======================================================================
æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯
======================================================================
æ€»å‚æ•°é‡: 405,234,689
å¯è®­ç»ƒå‚æ•°: 405,234,689
FP32å†…å­˜: 1.51 GB
FP16å†…å­˜: 0.75 GB

ç¼–ç å™¨å‚æ•°: 355,412,992 (87.7%)
è§£ç å™¨å‚æ•°: 49,821,697 (12.3%)

======================================================================
æ¨¡å‹å±‚ç»“æ„ (å‰10å±‚)
======================================================================
encoder.module.embeddings.word_embeddings.weight   torch.Size([50265, 1024])      51,471,360
encoder.module.embeddings.position_embeddings.wei  torch.Size([514, 1024])           526,336
encoder.module.embeddings.token_type_embeddings.w  torch.Size([1, 1024])               1,024
encoder.module.embeddings.LayerNorm.weight         torch.Size([1024])                  1,024
encoder.module.embeddings.LayerNorm.bias           torch.Size([1024])                  1,024
encoder.module.encoder.layer.0.attention.self.que  torch.Size([1024, 1024])        1,048,576
encoder.module.encoder.layer.0.attention.self.key  torch.Size([1024, 1024])        1,048,576
encoder.module.encoder.layer.0.attention.self.val  torch.Size([1024, 1024])        1,048,576
encoder.module.encoder.layer.0.attention.output.d  torch.Size([1024, 1024])        1,048,576
encoder.module.encoder.layer.0.attention.output.L  torch.Size([1024])                  1,024
...
```

#### ç¤ºä¾‹3: æå–ç‰¹å®šç»„ä»¶

```python
# åŠ è½½æ¨¡å‹
checkpoint = torch.load('model.pt', map_location='cpu')
model = checkpoint[0]

# 1. æå–RoBERTaç¼–ç å™¨
roberta_model = model.encoder.module
torch.save(roberta_model.state_dict(), 'roberta_encoder.pt')

# 2. æå–è§£ç å™¨
decoder = model.decoder
torch.save(decoder.state_dict(), 'qat_decoder.pt')

# 3. æå–ç‰¹å®šå±‚æƒé‡
# è·å–ç¬¬ä¸€ä¸ªGATå±‚çš„æƒé‡
gat_weight = model.decoder.qat.layers[0][0].lin.weight
print(f"GAT Layer 0 æƒé‡å½¢çŠ¶: {gat_weight.shape}")  # [1024, 1024]

# è·å–æ³¨æ„åŠ›å±‚æƒé‡
attn_q = model.decoder.qat.layers[0][2].q_proj.weight
attn_k = model.decoder.qat.layers[0][2].k_proj.weight
attn_v = model.decoder.qat.layers[0][2].v_proj.weight
print(f"æ³¨æ„åŠ›å±‚ Q/K/V æƒé‡å½¢çŠ¶: {attn_q.shape}")
```

#### ç¤ºä¾‹4: ç”¨äºæ¨ç†

```python
# åŠ è½½æ¨¡å‹
checkpoint = torch.load('model.pt', map_location='cpu')
model, args = checkpoint[0], checkpoint[1]

# å‡†å¤‡æ¨ç†
model.encoder.to('cuda:0')
model.decoder.to('cuda:1')
model.eval()

# æ¨ç†å•ä¸ªæ ·æœ¬
with torch.no_grad():
    # input_data = ... (å‡†å¤‡è¾“å…¥æ•°æ®)
    logits, rpe = model(*input_data, qids=['test_q1'])
    
    # è·å–é¢„æµ‹
    prediction = logits.argmax(1)
    confidence = torch.softmax(logits, dim=1).max(1)[0]
    
    print(f"é¢„æµ‹ç­”æ¡ˆ: {chr(ord('A') + prediction.item())}")
    print(f"ç½®ä¿¡åº¦: {confidence.item():.4f}")

# æ‰¹é‡æ¨ç†
predictions = []
for batch in test_loader:
    with torch.no_grad():
        logits, _ = model(*batch)
        preds = logits.argmax(1)
        predictions.extend(preds.cpu().tolist())

print(f"é¢„æµ‹ç»“æœ: {predictions[:10]}...")  # æ˜¾ç¤ºå‰10ä¸ª
```

#### ç¤ºä¾‹5: è½¬æ¢ä¸ºstate_dictæ ¼å¼ï¼ˆæ›´è½»é‡ï¼‰

```python
# åŠ è½½å®Œæ•´æ¨¡å‹
checkpoint = torch.load('model.pt')
model, args = checkpoint[0], checkpoint[1]

# ä»…ä¿å­˜æƒé‡ï¼ˆä¸ä¿å­˜æ¨¡å‹ç»“æ„ï¼‰
torch.save({
    'encoder_state_dict': model.encoder.state_dict(),
    'decoder_state_dict': model.decoder.state_dict(),
    'model_config': {
        'k': args.k,
        'transformer_dim': args.transformer_dim,
        'num_heads': args.num_heads,
        'max_seq_len': args.max_seq_len,
        'num_relation': args.num_relation,
    },
    'training_args': args
}, 'model_state_dict.pt')

# åŠ è½½state_dictï¼ˆéœ€è¦å…ˆé‡å»ºæ¨¡å‹ç»“æ„ï¼‰
from modeling.modeling_qat import LM_QAT

checkpoint = torch.load('model_state_dict.pt')
config = checkpoint['model_config']
args = checkpoint['training_args']

# é‡å»ºæ¨¡å‹
model = LM_QAT(
    args, args.encoder,
    k=config['k'],
    n_ntype=4,
    n_etype=config['num_relation'],
    fc_dim=512,
    n_fc_layer=0,
    p_fc=0.1,
    concept_dim=config['transformer_dim']
)

# åŠ è½½æƒé‡
model.encoder.load_state_dict(checkpoint['encoder_state_dict'])
model.decoder.load_state_dict(checkpoint['decoder_state_dict'])
```

### 12.5 å¸¸è§æ“ä½œ

#### æŸ¥çœ‹æ¨¡å‹é…ç½®
```python
checkpoint = torch.load('model.pt', map_location='cpu')
args = checkpoint[1]

print(f"æ•°æ®é›†: {args.dataset}")
print(f"æ‰¹æ¬¡å¤§å°: {args.batch_size}")
print(f"å­¦ä¹ ç‡: encoder={args.encoder_lr}, decoder={args.decoder_lr}")
print(f"æ¨¡å‹ç»´åº¦: {args.transformer_dim}")
print(f"è®­ç»ƒè½®æ•°: {args.n_epochs}")
```

#### æ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹
```python
model1 = torch.load('model_epoch10.pt')[0]
model2 = torch.load('model_epoch20.pt')[0]

# æ¯”è¾ƒå‚æ•°å·®å¼‚
diff_count = 0
for (n1, p1), (n2, p2) in zip(model1.named_parameters(), 
                               model2.named_parameters()):
    if not torch.equal(p1, p2):
        diff = (p1 - p2).abs().mean()
        print(f"{n1}: å¹³å‡å·®å¼‚ = {diff:.6f}")
        diff_count += 1

print(f"\næ€»å…± {diff_count} ä¸ªå‚æ•°å‘ç”Ÿå˜åŒ–")
```

#### æ¨¡å‹å‹ç¼©
```python
import gzip

# å‹ç¼©ä¿å­˜
with gzip.open('model.pt.gz', 'wb') as f:
    torch.save([model, args], f)

# åŠ è½½å‹ç¼©æ¨¡å‹
with gzip.open('model.pt.gz', 'rb') as f:
    checkpoint = torch.load(f)
    
# å¤§å°å¯¹æ¯”
import os
original_size = os.path.getsize('model.pt') / (1024**2)
compressed_size = os.path.getsize('model.pt.gz') / (1024**2)
print(f"åŸå§‹å¤§å°: {original_size:.2f} MB")
print(f"å‹ç¼©å: {compressed_size:.2f} MB")
print(f"å‹ç¼©ç‡: {(1 - compressed_size/original_size)*100:.1f}%")
```

---

## 13. æ€»ç»“

### æ ¸å¿ƒåˆ›æ–°ç‚¹

1. **å…³ç³»æ„ŸçŸ¥çš„å›¾Transformer**
   - èåˆå…ƒè·¯å¾„ä¿¡æ¯
   - ç›¸å¯¹ä½ç½®ç¼–ç  (RPE)
   - è¾¹ç±»å‹æ„ŸçŸ¥çš„æ³¨æ„åŠ›

2. **æ–‡æœ¬-å›¾è°±æ·±åº¦èåˆ**
   - GloVeåŒ¹é…æœºåˆ¶
   - åŒå‘æ³¨æ„åŠ› (GAT + LM Attention)
   - å¤šå±‚ä¿¡æ¯ä¼ æ’­

3. **é«˜æ•ˆè®­ç»ƒç­–ç•¥**
   - åŒGPUå¹¶è¡Œ
   - æ··åˆç²¾åº¦è®­ç»ƒ
   - æ¸è¿›å¼å¾®è°ƒ

### æ€§èƒ½æŒ‡æ ‡

**CommonsenseQA (å®˜æ–¹æµ‹è¯•é›†)**
- Accuracy: ~79.8%
- è®­ç»ƒæ—¶é—´: ~4å°æ—¶ (2x V100)
- å†…å­˜å ç”¨: ~16GB (FP16)

---


